{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prj js object\n",
    "js object\n",
    "const prj = {Id: 8,\n",
    "    number: \"008\",\n",
    "    title: \"Object segmentation with YOLO\",\n",
    "    info: \"Package segmentation\",\n",
    "    subInfo: \"subinfo\",\n",
    "    imgPath: thb[5],\n",
    "    category: \"cat-c\",\n",
    "    dataSource: \"link\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: explain code into paragraphs briefly and at last provide code with proper comments.\n",
    "Style: Academic\n",
    "Tone: Professional\n",
    "Audience: 30-year old\n",
    "Format: Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "In this project, we leverage the YOLO (You Only Look Once) architecture, specifically tailored for segmenting objects within images. The project model initialization, training, and making predictions on an image. We’ll explore how pre-trained models are used and fine-tuned for different datasets, enhancing efficiency and generalization.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step1\n",
    "yolo predict model=\"yolov8s-seg.pt\" source=\"https://ultralytics.com/images/bus.jpg\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "The model being used is YOLOv8s-seg, which is specifically designed for segmentation tasks. The -seg suffix indicates that it’s a segmentation model.The !yolo predict command is used to make predictions with the specified model.The source parameter specifies the input image URL: \"https://ultralytics.com/images/bus.jpg\". we use yolo to segment different classes in an given image.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO model for instance segmentation\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolov8n-seg.pt\")\n",
    "\n",
    "# Train the model using the specified configuration\n",
    "results = model.train(data=\"package-seg.yaml\", epochs=30, imgsz=640)\n",
    "\n",
    "# Load a pre-trained model (if available)\n",
    "loaded_model = YOLO(\"/contnet/runs/segment/weights/bes.pt\")\n",
    "\n",
    "# Make predictions on an image\n",
    "image_path = \"path/to/your/image.jpg\"\n",
    "result = model.predict(image_path, save=True)  # Save segmentation results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Initialization and Training:\n",
    "We start by importing the necessary libraries. The ultralytics library provides tools for working with YOLO models.\n",
    "Next, we create an instance of the YOLO model using the pre-trained weights file \"yolov8n-seg.pt\". This model is specifically designed for instance segmentation tasks.\n",
    "We then train the model using the \"package-seg.yaml\" configuration file. The training process runs for 30 epochs with an input image size of 640x640 pixels.\n",
    "The results variable stores information about the training process, including loss values, accuracy metrics, and other relevant data.\n",
    "Loading a Pre-Trained Model:\n",
    "We load another YOLO model from the file \"/contnet/runs/segment/weights/bes.pt\". This model might have been trained previously or obtained from another source.\n",
    "The loaded_model variable holds this pre-trained model.\n",
    "Prediction on an Image:\n",
    "Finally, we make predictions using the model.predict() method. We provide the path to an image (specified as \"img-path\"), and the model generates instance segmentation results.\n",
    "The save=True argument indicates that the predictions should be saved (e.g., as masks or contours) for further analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "image 1/1 /content/datasets/package-seg/test/images/5547_zl20230718_003_png_jpg.rf.4969ed3a70f791acf8bfa3dfbd7aaa95.jpg: 640x640 6 packages, 25.6ms\n",
    "Speed: 1.8ms preprocess, 25.6ms inference, 6.2ms postprocess per image at shape (1, 3, 640, 640)\n",
    "Results saved to runs/segment/train22\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

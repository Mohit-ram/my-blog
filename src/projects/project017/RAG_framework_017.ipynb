{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prj js object\n",
    "js object\n",
    "const prj = {Id: 17,\n",
    "    number: \"017\",\n",
    "    title: \"LangChain: RAG Framework Document embedding\",\n",
    "    info: \"Retrieval-Agumented Generation Framework in Langchain, Data ingestion, Data chunking, Data embedding\",\n",
    "    subInfo: \"LAngchain, Ollama, OpenAI, HuggingFace, Embeddings, Text Loaders, Text Splitters \",\n",
    "    imgPath: thb[17],\n",
    "    category: \"cat-c\",\n",
    "    dataSource: \"link\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: explain code into paragraphs briefly and at last provide code with proper comments.\n",
    "Style: Academic\n",
    "Tone: Professional and 1st person\n",
    "Audience: 30-year old\n",
    "Format: Text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Retrieval-Augmented Generation (RAG) is an advanced AI framework designed to enhance the performance of large language models (LLMs) by integrating them with external data retrieval mechanisms. This approach addresses some of the inherent limitations of LLMs, such as the tendency to generate outdated or inaccurate information, by grounding their responses in up-to-date and authoritative sources.\n",
    "<br/>\n",
    "<h5> How RAG works </h5>\n",
    "Query Processing: The system receives a query from the user and processes it to understand the context and information needs.<br>\n",
    "Information Retrieval: The system searches for relevant information from external sources, such as databases, documents, or the web. This step involves generating vector embeddings of the query and performing similarity searches to find the most relevant data2.<br/>\n",
    "Augmentation of the Query: The retrieved information is used to augment the original query, providing additional context and details that the LLM can use to generate a more accurate response1.<br/>\n",
    "Response Generation: The augmented query is fed into the LLM, which generates a response based on both its internal knowledge and the retrieved external information2.\n",
    "Delivery of the Response: The system delivers the final response to the user, ensuring that it is both accurate and contextually relevant1.\n",
    "<br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Step1\n",
    "<p>Project intro</p>\n",
    "      <h4></h4>\n",
    "      <Code\n",
    "        code={`\n",
    "          \n",
    "          `}\n",
    "      />\n",
    "      <p>\n",
    "        <br />\n",
    "        <br />\n",
    "      </p>\n",
    "\n",
    "<div className=\"d-block text-center\">\n",
    "        <img\n",
    "          src={img02}\n",
    "          alt=\"result1\"\n",
    "          style={{ height: \"300px\", width: \"300px\" }}\n",
    "        />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Implementation of RAG with Langchain</h4>\n",
    "<h5>Stage1: Data Ingestion </h5>\n",
    "<p>\n",
    "Data ingestion in a Retrieval-Augmented Generation (RAG) framework involves several key steps to ensure that the external data is effectively integrated and utilized by the language model. \n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1 :Data Ingestion\n",
    "# Importing necessary classes from langchain_community.document_loaders\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader, WikipediaLoader\n",
    "\n",
    "# Loading a text file\n",
    "# Create a TextLoader instance for the file 'speech.txt'\n",
    "loader = TextLoader('sample.txt')\n",
    "text_documents = loader.load()\n",
    "\n",
    "# Reading a PDF file\n",
    "# Create a PyPDFLoader instance for the file 'attention.pdf'\n",
    "loader = PyPDFLoader('sample.pdf')\n",
    "docs = loader.load()\n",
    "\n",
    "# Reading from a website\n",
    "# Import BeautifulSoup for HTML parsing\n",
    "import bs4\n",
    "# Create a WebBaseLoader instance for the given URL\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(parse_only=bs4.SoupStrainer(class_=(\"post-title\", \"post-content\", \"post-header\")))\n",
    ")\n",
    "loader.load()\n",
    "# Reading from a Wikipedia article\n",
    "# Create a WikipediaLoader instance to query \"any article_name\" and load a maximum of 2 documents\n",
    "docs = WikipediaLoader(query=\"article_name\", load_max_docs=2).load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Stage2 :Data chunking</h5>\n",
    "<p>\n",
    "Data chunking is a technique used to divide large datasets or documents into smaller, more manageable pieces called chunks. This process is essential in various fields, including natural language processing, data storage, and data transmission, to ensure efficient processing, retrieval, and analysis.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Chunking\n",
    "# Importing necessary classes from langchain_text_splitters\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter, HTMLHeaderTextSplitter, RecursiveJsonSplitter\n",
    "\n",
    "# Recursive Character Splitter\n",
    "# Create a RecursiveCharacterTextSplitter instance with chunk size of 500 and overlap of 50\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "# Split documents into chunks\n",
    "final_documents = text_splitter.split_documents(docs)  # for input in documents\n",
    "text = text_splitter.create_documents(\"list of texts\")  # for input in text\n",
    "\n",
    "# Character Splitter\n",
    "# Create a CharacterTextSplitter instance with separator as double newline, chunk size of 100, and overlap of 20\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=100, chunk_overlap=20)\n",
    "text_splitter.split_documents(docs)\n",
    "\n",
    "# HTML Header Splitter\n",
    "# Define headers to split on\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\")\n",
    "]\n",
    "# Create an HTMLHeaderTextSplitter instance with specified headers\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "# Split HTML content into chunks\n",
    "html_header_splits = html_splitter.split_text(html_string)\n",
    "\n",
    "# JSON Splitter\n",
    "# Create a RecursiveJsonSplitter instance with max chunk size of 300\n",
    "json_splitter = RecursiveJsonSplitter(max_chunk_size=300)\n",
    "# Split JSON data into chunks\n",
    "json_chunks = json_splitter.split_json(json_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Stage3: Data Embedding</h5>\n",
    "<p>\n",
    "Embeddings are numerical representations of text that capture semantic meaning, making them useful for various natural language processing tasks such as similarity searches and information retrieval.\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document/text Embedding\n",
    "# Importing necessary modules\n",
    "from dotenv import load_dotenv\n",
    "# Load all the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI embeddings - paid source\n",
    "# Set the OpenAI API key from environment variables\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# Create an instance of OpenAIEmbeddings with specified model and dimension\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimension=1024)\n",
    "text = \"This is a tutorial on OPENAI embedding\"\n",
    "# Generate an embedding for the text query\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "# Ollama embeddings - open source\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "# Create an instance of OllamaEmbeddings for model of your choics model name from ollama web\n",
    "embeddings = OllamaEmbeddings(model=\"model_name\")\n",
    "# Generate embeddings for a list of documents\n",
    "query_result = embeddings.embed_documents(\"[list of documents]\")\n",
    "# Generate an embedding for a single text query\n",
    "query_result = embeddings.embed_query(\"single text query\")\n",
    "\n",
    "# Hugging Face embeddings - open source\n",
    "# Set the Hugging Face API token from environment variables\n",
    "os.environ['HF_TOKEN'] = os.getenv(\"HF_TOKEN\")\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# Create an instance of HuggingFaceEmbeddings with the specified model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"any_model_name\")\n",
    "# Generate an embedding for a single text query\n",
    "query_result = embeddings.embed_query(\"any single text\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
